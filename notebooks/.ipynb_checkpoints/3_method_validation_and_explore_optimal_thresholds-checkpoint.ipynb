{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3) Method validation and find optimal thresholds\n",
    "\n",
    "In this notebook, we use again the surrogate methods to validate our method and show how we would find optimal thresholds for the acceptance test.\n",
    "\n",
    "In order to validate the methodology, we expand the surrogate simulation to all recorded spike trains and use the simulated calcium spine traces with their respective spike train as ground-truth monosynaptic connections. Similarly to Part 2, we can then obtain the GT-Rs and Test-Rs distributions. In addition to these, we introduce here a new surrogate distribution of R values named noGT-Rs, which is the distribution of R-values from the second-best match units. As we collect the distributions from all units, we denote them as GT-R-all, noGT-R-all, and Test-R-all.\n",
    "\n",
    "Last, we apply a performence test using the GT-R-all and noGT-R-all to evaluate our method and explore the optimal thresholds. Our goal is to find two optimal quantile values for the Test-Rs and GT-Rs distributions, denoted as Q-test and Q-GT, respectively. \n",
    "\n",
    "We can use the pre-computed GT-R-all and noGT-R-all R-values to compute, for each tested quantile, the following values:\n",
    "\n",
    "- number of true positives (#TP): surrogate tests that correctly identify the right best match from the GT-R-all distribution\n",
    "- number of false negatives (#FN): surrogate tests that incorrectly don't find the right best match from the GT-R-all distribution\n",
    "- number of true negatives (#TN): surrogate tests that correctly fails to identify a monosynaptic connection from the noGT-Rs distribution\n",
    "- number of false positives (#FP): surrogate tests that incorrectly identify a monosynaptic connection from the noGT-R-all distribution\n",
    "\n",
    "From these values, we can compute the F-score for different Q-test and Q-GT values and find the optimal values that yield the highest F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import quantities as pq\n",
    "import scipy.signal as ss\n",
    "import scipy.stats as stats\n",
    "import scipy.ndimage as ndimg\n",
    "from joblib import Parallel, delayed\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from imaging_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nwb file\n",
    "nwb_file_path = \"...\"\n",
    "_, imag, _, _, mea_duration, ds_idxs = load_nwb_file(nwb_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved variables\n",
    "saved_var1 = np.load('saved_data_P1.npz',allow_pickle=True)\n",
    "saved_var2 = np.load('saved_data_P2.npz',allow_pickle=True)\n",
    "\n",
    "spiketrains = saved_var1['spiketrains']\n",
    "best_match = saved_var1['best_match']\n",
    "best_r = saved_var1['best_r']\n",
    "individual_frs_ds_dff = saved_var1['individual_frs_ds_dff'] # convolved spike trains\n",
    "keep = saved_var1['keep'] # indices to exclude network bursts\n",
    "\n",
    "release_probs = saved_var2['release_probs'] # simulated release probablity\n",
    "std_noise = saved_var2['std_noise'] # standard deviation of measure noise\n",
    "std_signal = saved_var2['std_signal'] # standard deviation of signal (spine trace)\n",
    "baseline_signal = saved_var2['baseline_signal'] # baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate GT surrogates for all recorded spike trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compute surrogates for all recorded spike trains with the simulated release probablity and recording noise as used in part2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute surrogates or directly load from example data\n",
    "\n",
    "n_surrogates = 1000 # number of surrogates\n",
    "\n",
    "gt_surrogates_all = generate_surrogates(n_surrogates, imag.get_num_frames(), release_probs, spiketrains,best_match,\n",
    "                                        ds_idxs, std_noise, std_signal, baseline_signal, 100, 25, method='GT_all')\n",
    "timestamps = np.linspace(0, duration, len(gt_surrogates_all[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spike_id = best_match\n",
    "plt.figure()\n",
    "plt.plot(timestamps, gt_surrogates_all[spike_id, ::100, :].T, alpha=0.8)\n",
    "plt.plot(timestamps, individual_frs_ds_dff[spike_id], color=\"k\", alpha=0.8)\n",
    "plt.plot(spiketrains[spike_id], np.zeros_like(spiketrains[spike_id]), \"k\", ls=\"\", marker=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute GT-Rs and noGT-Rs\n",
    "We then compute the distributions of GT-Rs and noGT-Rs for surrogates from all units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see function documentation for details\n",
    "corr_r, GT_r_all, no_GT_r_all = compute_corr_r(gt_surrogates_all, n_surrogates, individual_frs_ds_dff, keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compute test-Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see function documentation for details\n",
    "n_jobs = 12 # number of workers for parallel computating\n",
    "test_r_all = compute_test_r(gt_surrogates_all, n_surrogates, corr_r, individual_frs_ds_dff, keep, n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance test\n",
    "\n",
    "After computing all surrogate R-distributions, we can perform the acceptance test presented in part2 for each GT and noGT example, for different values of `Q_test` and `Q_gt`. To recap, a monosynaptic connection is accepted is the R-value between the convolved spike train and the spine trace (in this case simulated) is above both the R-value thresholds given by these quantiles from the Test-Rs and GT-Rs distribitions, respectively.\n",
    "\n",
    "After computing #TP, #FN, #TN and #FP, we use them to calculate the F-score, that we use as performance metric for each pair of (`Q_test`, `Q_gt`) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two threholds for accepting a mapped functional synaptic connection\n",
    "# Q_test: Q threshold on test-Rs\n",
    "# Q_gt: Q threshold on GT_Rs (R need to be within)\n",
    "\n",
    "N_values = 100 # number of quantile values\n",
    "Q_test = np.round(np.linspace(0, 1, N_values, endpoint=True), decimals=3) # percentile value\n",
    "Q_gt = np.round(np.linspace(0, 1, N_values, endpoint=True), decimals=3)\n",
    "\n",
    "conf_matrix = []\n",
    "\n",
    "for r in Q_test:\n",
    "    for q in Q_gt:\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        matrix = []\n",
    "\n",
    "        for i in range(len(spiketrains)):\n",
    "            gt_rs = corr_r[i, :, i]            \n",
    "            \n",
    "            r1 = np.nanquantile(np.concatenate(test_r_all[i]), r) \n",
    "            r2 = np.nanquantile(gt_rs, q)\n",
    "            \n",
    "            tp = len(np.where(GT_r_all[i][np.isfinite(GT_r_all[i])] > max(r1, r2))[0])\n",
    "            fn = len(GT_r_all[i]) - tp\n",
    "            fp = len(np.where(no_GT_r_all[i] > max(r1, r2))[0])\n",
    "            tn = len(no_GT_r_all[i]) - fp\n",
    "\n",
    "            TP = tp + TP\n",
    "            FN = fn + FN\n",
    "            FP = fp + FP\n",
    "            TN = tn + TN\n",
    "\n",
    "        matrix.extend([TP,FN,FP,TN])\n",
    "        conf_matrix.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute evaluation terms from confusion matrix\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for i in conf_matrix:\n",
    "    tp, fn, fp, tn = i\n",
    "#     print(tp, fn)\n",
    "    recall.append(tp / (tp + fn))\n",
    "    \n",
    "    if (tp + fp) != 0:\n",
    "        precision.append(tp / (tp + fp))\n",
    "    else:\n",
    "        precision.append(np.nan)   \n",
    "\n",
    "# reshape evaluation terms\n",
    "precision = np.array(precision).reshape(N_values, N_values)\n",
    "recall = np.array(recall).reshape(N_values, N_values)\n",
    "\n",
    "beta = 0.5 # factor to calculate F-score\n",
    "F_score = (1 + np.square(beta))*precision*recall/(np.square(beta)*precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of F-score\n",
    "\n",
    "df = DataFrame(F_score, index=Q_test, columns=Q_gt)\n",
    "fig=plt.figure()\n",
    "ax = sns.heatmap(df)\n",
    "print(np.nanmax(F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the thresholds with maximum F-score\n",
    "\n",
    "optimal_Q_test = Q_test[np.where(F_score == np.nanmax(F_score))[0]]\n",
    "optimal_Q_gt = Q_gt[np.where(F_score == np.nanmax(F_score))[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Q_gt:\", optimal_Q_gt)\n",
    "print(\"Q_test:\", optimal_Q_test)\n",
    "print(\"max F-score:\", np.nanmax(F_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
